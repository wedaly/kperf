# count defines how many runners in the group.
count: 10

# This simulates worst-case behavior for Cilium:
# every agent hammering apiserver with stale LIST requests for CiliumIdentity and CiliumEndpoint.
# The request rate is much, much higher than what we'd expect to see in production with
# client-go exponential backoff configured, so if apiserver can survive this onslaught it can
# survive anything Cilium throws at it.
loadProfile:
  version: 1
  description: cilium list profile
  spec:
    rate: 20
    total: 100000
    # 5k node cluster, one cilium agent per node
    # divided by the number of runners.
    conns: 500
    client: 500

    contentType: json
    disableHTTP2: false

    # 50/50 mix of ciliumidentity and ciliumendpoint queries.
    # We're simulating with CilumEndpointSlice disabled here, on the assumption that CES will always
    # have lower count than CEP, so if we can survive with CEP only then we're in good shape.
    requests:
      - staleList:
          group: cilium.io
          version: v2
          resource: ciliumidentity
        shares: 1000 # Has 50% chance = 1000 / (1000 + 1000)
      - staleList:
          group: cilium.io
          version: v2
          resource: ciliumendpoint
        shares: 1000 # Has 50% chance = 1000 / (1000 + 1000)

# nodeAffinity defines how to deploy runners into dedicated nodes which have specific labels.
nodeAffinity:
  kperf:
    - "true"